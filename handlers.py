"""
í…”ë ˆê·¸ë¨ ë´‡ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë“¤
"""

from langchain_ollama import OllamaEmbeddings
from telegram import ReplyKeyboardRemove, Update
from telegram.ext import ContextTypes, ConversationHandler

from langchain_community.vectorstores import FAISS
from bot_config import (
    logger,
    reply_markup_models,
    reply_markup_commands,
    CHOOSING,
    TYPING_REPLY,
    TYPING_CHOICE,
    SUPPORTED_MODELS,
)

FAISS_INDEX_PATH = "faiss_ai_sample_index"


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """'/start' ëª…ë ¹ì–´ ì²˜ë¦¬"""
    if not update.message or not update.effective_user:
        logger.warning("ì—…ë°ì´íŠ¸ì— ë©”ì‹œì§€ë‚˜ ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    user = update.effective_user
    welcome_message = (
        f"ì•ˆë…•í•˜ì„¸ìš” {user.name}ë‹˜! ğŸ‘‹\n\n"
        "ì¹´ë©”ë¼ ë§¤ë‰´ì–¼ ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!\n"
        "/help ëª…ë ¹ì–´ë¡œ ì‚¬ìš©ë²•ì„ í™•ì¸í•˜ì„¸ìš”."
    )

    await update.message.reply_text(welcome_message, reply_markup=reply_markup_models)


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """'/help' ëª…ë ¹ì–´ ì²˜ë¦¬"""
    if not update.message:
        logger.warning("ì—…ë°ì´íŠ¸ì— ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    help_text = (
        "ğŸ“¸ <b>ì¹´ë©”ë¼ ë§¤ë‰´ì–¼ ë´‡ ì‚¬ìš©ë²•</b>\n\n"
        "ğŸ”¹ /start - ë´‡ ì‹œì‘\n"
        "ğŸ”¹ /help - ë„ì›€ë§ ë³´ê¸°\n"
        "ğŸ”¹ /manual - ì„¤ëª…ì„œ ê²€ìƒ‰\n\n"
        "/manual ëª…ë ¹ì–´ë¡œ ì‹œì‘í•´ ì£¼ì„¸ìš”!"
    )
    await update.message.reply_html(help_text)


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ì¼ë°˜ ë©”ì‹œì§€ ì²˜ë¦¬"""
    if not update.message or not update.effective_user:
        logger.warning("ì—…ë°ì´íŠ¸ì— ë©”ì‹œì§€ë‚˜ ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    user_message = update.message.text
    user_name = update.effective_user.first_name

    logger.info(f"ë©”ì‹œì§€ ìˆ˜ì‹  - ì‚¬ìš©ì: {user_name}, ë‚´ìš©: {user_message}")

    response = (
        f"ì•ˆë…•í•˜ì„¸ìš” {user_name}ë‹˜! ğŸ“¸\n\n"
        f"'{user_message}'ì— ëŒ€í•œ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.\n"
        "í˜„ì¬ëŠ” ê¸°ë³¸ ì‘ë‹µë§Œ ì œê³µë©ë‹ˆë‹¤."
    )

    await update.message.reply_text(response)


async def start_manual_conversation(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> int:
    """ë§¤ë‰´ì–¼ ê²€ìƒ‰ ëŒ€í™” ì‹œì‘"""
    if not update.message or not update.effective_user:
        logger.warning("ì—…ë°ì´íŠ¸ì— ë©”ì‹œì§€ë‚˜ ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return ConversationHandler.END

    await update.message.reply_text(
        "ë‹¤ìŒ ì¹´ë©”ë¼ ëª¨ë¸ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:\n",
        reply_markup=reply_markup_models,
    )

    return CHOOSING


async def camera_model_choice(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> int:
    """ì¹´ë©”ë¼ ëª¨ë¸ ì„ íƒ ì²˜ë¦¬"""
    if not update.message or context.user_data is None:
        logger.warning("ë©”ì‹œì§€ë‚˜ ì‚¬ìš©ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return TYPING_CHOICE

    model = update.message.text

    # ì§€ì›í•˜ëŠ” ëª¨ë¸ì¸ì§€ í™•ì¸
    if model not in SUPPORTED_MODELS:
        await update.message.reply_text(
            f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. {', '.join(SUPPORTED_MODELS)} ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.",
            reply_markup=reply_markup_models,
        )
        return CHOOSING

    context.user_data.update({"choice": model})

    await update.message.reply_text(f"{model}ì˜ ì–´ë–¤ ì ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")

    return TYPING_REPLY


async def handle_fallback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ì˜ëª»ëœ ì…ë ¥ ì²˜ë¦¬"""
    if not update.message or not update.effective_user:
        logger.warning("ì—…ë°ì´íŠ¸ì— ë©”ì‹œì§€ë‚˜ ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return TYPING_CHOICE

    await update.message.reply_text(
        f"{', '.join(SUPPORTED_MODELS)} ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
        reply_markup=reply_markup_models,
    )

    return CHOOSING


async def query_manual(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ë§¤ë‰´ì–¼ ì§ˆë¬¸ ì²˜ë¦¬"""
    if not update.message or not context.user_data:
        logger.warning("ì—…ë°ì´íŠ¸ì— ë©”ì‹œì§€ë‚˜ ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return TYPING_CHOICE

    query = update.message.text
    model = context.user_data.get("choice", "Unknown")

    if not query or not model:
        await update.message.reply_text(
            "ì§ˆë¬¸ì´ ë¹„ì–´ìˆê±°ë‚˜ ëª¨ë¸ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            reply_markup=reply_markup_models,
        )
        return TYPING_CHOICE

    embeddings_ollama = OllamaEmbeddings(model="bge-m3")
    local_faiss = FAISS.load_local(
        FAISS_INDEX_PATH,
        embeddings_ollama,
        allow_dangerous_deserialization=True,
    )

    retriever = local_faiss.as_retriever(
        search_kwargs={"k": 1, "temperature": 0.1, "filter": {"model": model}}
    )

    docs = retriever.invoke(query)

    formatted_docs = []

    for i, (doc) in enumerate(docs):
        metadata = doc.metadata if hasattr(doc, "metadata") else {}

        source_info = []

        if "model" in metadata:
            source_info.append(f"ëª¨ë¸: {metadata['model']}")

        if "page_no" in metadata:
            source_info.append(f"í˜ì´ì§€: {metadata['page_no']}")

        if len(source_info) > 0:
            formatted_docs.append(
                f"ğŸ“š ì°¸ê³  í˜ì´ì§€ {metadata['page_no']}\n"
                f"â€¢ {' | '.join(source_info) if source_info else 'ì¶œì²˜ ì •ë³´ ì—†ìŒ'}\n"
                # f"â€¢ ë‚´ìš©: {doc.page_content[:100]}{'...' if len(doc.page_content) > 100 else ''}"
            )

    result = ""
    for i, doc in enumerate(docs):
        result += "<code>\n"
        result += f">> {doc.page_content}\n\n"
        result += f"{formatted_docs[i]}"
        result += "</code>"

    help_text = (
        f"ğŸ” {model}: {query}\n\n"
        "ğŸ”¹ <b>ê²€ìƒ‰ ê²°ê³¼</b>:\n"
        f"{result}\n\n"
        "ğŸ”¹ ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹ ê°€ìš”?\n"
        "ğŸ”¹ 'DONE'ì„ ì„ íƒí•´ì„œ ëŒ€í™”ë¥¼ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
    )

    await update.message.reply_html(
        help_text,
        reply_markup=reply_markup_commands,
    )

    return TYPING_REPLY


async def done(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ëŒ€í™” ì¢…ë£Œ"""
    if not update.message or not context.user_data:
        logger.warning("ì—…ë°ì´íŠ¸ì— ë©”ì‹œì§€ë‚˜ ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return ConversationHandler.END

    user_data = context.user_data
    if "choice" in user_data:
        del user_data["choice"]

    await update.message.reply_text(
        "ğŸ¤– ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
        reply_markup=ReplyKeyboardRemove(),
    )

    user_data.clear()
    return ConversationHandler.END


def facts_to_str(user_data: dict[str, str]) -> str:
    """ì‚¬ìš©ì ë°ì´í„° í¬ë§·íŒ… í—¬í¼ í•¨ìˆ˜"""
    facts = [f"{key} - {value}" for key, value in user_data.items()]
    return "\n".join(facts).join(["\n", "\n"])
